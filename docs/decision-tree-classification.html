<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Ming Chen" />


<title>Decision Tree Classification</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Learning Apache Spark</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Getting Start
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="divider"></li>
    <li class="dropdown-header">Installations</li>
    <li>
      <a href="install.html">Installations</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Integrate Spark</li>
    <li>
      <a href="pyspark-on-rodeo.html">Integrate spark with Rodeo</a>
    </li>
    <li>
      <a href="pyspark-on-jupyter.html">Integrate spark with Jupyter</a>
    </li>
    <li>
      <a href="spark-on-jetstream-cloud.html">Spark on jetstream cloud</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Data Preparation
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01_entry_points_to_spark.html">Entry points to spark</a>
    </li>
    <li>
      <a href="02_rdd_object.html">RDD object</a>
    </li>
    <li>
      <a href="03_dataframe_object.html">DataFrame object</a>
    </li>
    <li>
      <a href="categorical-data.html">Categorial data</a>
    </li>
    <li>
      <a href="continuous-to-categorical-variable.html">Continuous variables to categorical variables</a>
    </li>
    <li>
      <a href="HashingTF-and-CountVectorizer.html">HashingTF and CountVectorizer</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Machine Learning
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="divider"></li>
    <li class="dropdown-header">Regression</li>
    <li>
      <a href="linear-regression.html">Linear regression</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Classification</li>
    <li>
      <a href="logistic-regression.html">Logistic regression</a>
    </li>
    <li>
      <a href="decision-tree-classification.html">Decision tree classification</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">More ML methods coming soon</li>
    <li class="divider"></li>
    <li>
      <a href="https://github.com/MingChen0919/learning-apache-spark/tree/master/legacy">Legacy</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Module Tuning and Evaluation
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="divider"></li>
    <li class="dropdown-header">Module Tuning</li>
    <li>
      <a href="regularization.html">Regularization</a>
    </li>
    <li>
      <a href="k-folds-cross-validation.html">K-folds Cross Validation</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/MingChen0919/learning-apache-spark">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="https://twitter.com/mingchen0919">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Decision Tree Classification</h1>
<h4 class="author"><em>Ming Chen</em></h4>
<h4 class="date"><em>6/6/2017</em></h4>

</div>


<div id="decision-tree-with-pyspark" class="section level2">
<h2>Decision tree with pyspark</h2>
<p><strong>Import data</strong></p>
<pre class="python"><code>cuse = spark.read.csv(&#39;data/cuse_binary.csv&#39;, header=True, inferSchema=True)
cuse.show(5)

+---+---------+---------+---+
|age|education|wantsMore|  y|
+---+---------+---------+---+
|&lt;25|      low|      yes|  0|
|&lt;25|      low|      yes|  0|
|&lt;25|      low|      yes|  0|
|&lt;25|      low|      yes|  0|
|&lt;25|      low|      yes|  0|
+---+---------+---------+---+
only showing top 5 rows</code></pre>
</div>
<div id="process-categorical-columns" class="section level2">
<h2>Process categorical columns</h2>
<p>The following code does three things with pipeline:</p>
<ul>
<li><code>StringIndexer</code> all categorical columns</li>
<li><code>OneHotEncoder</code> all categorical index columns</li>
<li><code>VectorAssembler</code> all feature columns into one vector column</li>
</ul>
<pre class="python"><code>from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler
from pyspark.ml import Pipeline

# categorical columns
categorical_columns = cuse.columns[0:3]

# build StringIndexer stages
stringindexer_stages = [StringIndexer(inputCol=c, outputCol=&#39;strindexed_&#39; + c) for c in categorical_columns]
# encode label column and add it to stringindexer_stages
stringindexer_stages += [StringIndexer(inputCol=&#39;y&#39;, outputCol=&#39;label&#39;)]

# build OneHotEncoder stages
onehotencoder_stages = [OneHotEncoder(inputCol=&#39;strindexed_&#39; + c, outputCol=&#39;onehot_&#39; + c) for c in categorical_columns]

# build VectorAssembler stage
feature_columns = [&#39;onehot_&#39; + c for c in categorical_columns]
vectorassembler_stage = VectorAssembler(inputCols=feature_columns, outputCol=&#39;features&#39;) 

# all stages
all_stages = stringindexer_stages + onehotencoder_stages + [vectorassembler_stage]

# build pipeline model
pipeline = Pipeline(stages=all_stages)

# fit pipeline model
pipeline_model = pipeline.fit(cuse)

# transform the data
final_columns = feature_columns + [&#39;features&#39;, &#39;label&#39;]
cuse_df = pipeline_model.transform(cuse).\
            select(final_columns)
            
cuse_df.show(5)

+-------------+----------------+----------------+-------------------+-----+
|   onehot_age|onehot_education|onehot_wantsMore|           features|label|
+-------------+----------------+----------------+-------------------+-----+
|(3,[2],[1.0])|       (1,[],[])|   (1,[0],[1.0])|(5,[2,4],[1.0,1.0])|  0.0|
|(3,[2],[1.0])|       (1,[],[])|   (1,[0],[1.0])|(5,[2,4],[1.0,1.0])|  0.0|
|(3,[2],[1.0])|       (1,[],[])|   (1,[0],[1.0])|(5,[2,4],[1.0,1.0])|  0.0|
|(3,[2],[1.0])|       (1,[],[])|   (1,[0],[1.0])|(5,[2,4],[1.0,1.0])|  0.0|
|(3,[2],[1.0])|       (1,[],[])|   (1,[0],[1.0])|(5,[2,4],[1.0,1.0])|  0.0|
+-------------+----------------+----------------+-------------------+-----+</code></pre>
<p><strong>Split data into training and test datasets</strong></p>
<pre class="python"><code>training, test = cuse_df.randomSplit([0.8, 0.2], seed=1234)</code></pre>
<p><strong>Build cross-validation model</strong></p>
<pre class="python"><code>## ======= build cross validation model ===========

# estimator
from pyspark.ml.regression import GeneralizedLinearRegression
from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier

dt = DecisionTreeClassifier(featuresCol=&#39;features&#39;, labelCol=&#39;label&#39;)

# parameter grid
from pyspark.ml.tuning import ParamGridBuilder
param_grid = ParamGridBuilder().\
    addGrid(dt.maxDepth, [2,3,4,5]).\
    build()
    
# evaluator
from pyspark.ml.evaluation import BinaryClassificationEvaluator
evaluator = BinaryClassificationEvaluator(rawPredictionCol=&quot;rawPrediction&quot;, metricName=&quot;areaUnderROC&quot;)

# build cross-validation model
from pyspark.ml.tuning import CrossValidator
cv = CrossValidator(estimator=dt, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=4)</code></pre>
<p><strong>Fit model</strong></p>
<pre class="python"><code># cv_model = cv.fit(training)
# To compare the results with R, here we use the entire dataset to fit the model.
cv_model = cv.fit(cuse_df)</code></pre>
<p><strong>Prediction</strong></p>
<pre class="python"><code># prediction
show_columns = [&#39;features&#39;, &#39;label&#39;, &#39;prediction&#39;, &#39;rawPrediction&#39;, &#39;probability&#39;]

pred_training_cv = cv_model.transform(training)
pred_test_cv = cv_model.transform(test)

pred_training_cv.select(show_columns).show(5, truncate=False)
pred_test_cv.select(show_columns).show(5, truncate=False)

+---------+-----+----------+-------------+----------------------------------------+
|features |label|prediction|rawPrediction|probability                             |
+---------+-----+----------+-------------+----------------------------------------+
|(5,[],[])|0.0  |1.0       |[203.0,237.0]|[0.46136363636363636,0.5386363636363637]|
|(5,[],[])|0.0  |1.0       |[203.0,237.0]|[0.46136363636363636,0.5386363636363637]|
|(5,[],[])|0.0  |1.0       |[203.0,237.0]|[0.46136363636363636,0.5386363636363637]|
|(5,[],[])|0.0  |1.0       |[203.0,237.0]|[0.46136363636363636,0.5386363636363637]|
|(5,[],[])|0.0  |1.0       |[203.0,237.0]|[0.46136363636363636,0.5386363636363637]|
+---------+-----+----------+-------------+----------------------------------------+
only showing top 5 rows

+---------+-----+----------+-------------+----------------------------------------+
|features |label|prediction|rawPrediction|probability                             |
+---------+-----+----------+-------------+----------------------------------------+
|(5,[],[])|0.0  |1.0       |[203.0,237.0]|[0.46136363636363636,0.5386363636363637]|
|(5,[],[])|0.0  |1.0       |[203.0,237.0]|[0.46136363636363636,0.5386363636363637]|
|(5,[],[])|0.0  |1.0       |[203.0,237.0]|[0.46136363636363636,0.5386363636363637]|
|(5,[],[])|0.0  |1.0       |[203.0,237.0]|[0.46136363636363636,0.5386363636363637]|
|(5,[],[])|0.0  |1.0       |[203.0,237.0]|[0.46136363636363636,0.5386363636363637]|
+---------+-----+----------+-------------+----------------------------------------+
only showing top 5 rows</code></pre>
<p><strong>Confusion matrix</strong></p>
<p>Pyspark doesn’t have a function to calculate the confusion matrix automatically, but we can still easily get a confusion matrix.</p>
<p>From the results below, we can see that pyspark and R got exactly the same confusion matrix.</p>
<pre class="python"><code>label_and_pred = cv_model.transform(cuse_df).select(&#39;label&#39;, &#39;prediction&#39;)
label_and_pred.rdd.zipWithIndex().countByKey()

# confusion matrix from pyspark
defaultdict(int,
            {Row(label=0.0, prediction=0.0): 897,
             Row(label=0.0, prediction=1.0): 203,
             Row(label=1.0, prediction=0.0): 270,
             Row(label=1.0, prediction=1.0): 237})
             
# confusion matrix from R
          Reference
Prediction   1   0
         1 237 203
         0 270 897</code></pre>
</div>
<div id="decision-tree-classification-with-r" class="section level2">
<h2>Decision tree classification with R</h2>
<pre class="r"><code>library(rpart)
library(caret)

# import data
cuse_binary = read.csv(&#39;data/cuse_binary.csv&#39;, header = TRUE)

# encode categorical columns in the same way as pyspark
cuse_binary$age = factor(cuse_binary$age, 
                         levels = names(sort(table(cuse_binary$age), decreasing = TRUE)))
cuse_binary$education = factor(cuse_binary$education,
                               levels = names(sort(table(cuse_binary$education), decreasing = TRUE)))
cuse_binary$wantsMore = factor(cuse_binary$wantsMore,
                               levels = names(sort(table(cuse_binary$wantsMore), decreasing = TRUE)))

# encode label column
cuse_binary$y = factor(cuse_binary$y,
                               levels = names(sort(table(cuse_binary$y))))

# fit decision tree
dt_fit = rpart(y ~ age + education + wantsMore, 
               data = cuse_binary, method = &#39;class&#39;)

# confusion matrix
pred_y = predict(dt_fit, type = &#39;class&#39;)
confusionMatrix(data = pred_y, reference = cuse_binary$y)</code></pre>
<pre class="python"><code>Confusion Matrix and Statistics

          Reference
Prediction   1   0
         1 237 203
         0 270 897
                                          
               Accuracy : 0.7057          
                 95% CI : (0.6827, 0.7279)
    No Information Rate : 0.6845          
    P-Value [Acc &gt; NIR] : 0.035460        
                                          
                  Kappa : 0.2934          
 Mcnemar&#39;s Test P-Value : 0.002408        
                                          
            Sensitivity : 0.4675          
            Specificity : 0.8155          
         Pos Pred Value : 0.5386          
         Neg Pred Value : 0.7686          
             Prevalence : 0.3155          
         Detection Rate : 0.1475          
   Detection Prevalence : 0.2738          
      Balanced Accuracy : 0.6415          
                                          
       &#39;Positive&#39; Class : 1  </code></pre>
</div>

<center>Copyright &copy; 2017 Ming Chen  & Wenqiang Feng. All rights reserved.</center>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
