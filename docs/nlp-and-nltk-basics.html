<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Ming Chen" />


<title>NLP and NLTK basics</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Learning Apache Spark</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Getting Start
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="divider"></li>
    <li class="dropdown-header">Installations</li>
    <li>
      <a href="install.html">Installations</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Integrate Spark</li>
    <li>
      <a href="pyspark-on-rodeo.html">Integrate spark with Rodeo</a>
    </li>
    <li>
      <a href="pyspark-on-jupyter.html">Integrate spark with Jupyter</a>
    </li>
    <li>
      <a href="spark-on-jetstream-cloud.html">Spark on jetstream cloud</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Data Preparation
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01_entry_points_to_spark.html">Entry points to spark</a>
    </li>
    <li>
      <a href="02_rdd_object.html">RDD object</a>
    </li>
    <li>
      <a href="03_dataframe_object.html">DataFrame object</a>
    </li>
    <li>
      <a href="categorical-data.html">Categorial data</a>
    </li>
    <li>
      <a href="continuous-to-categorical-variable.html">Continuous variables to categorical variables</a>
    </li>
    <li>
      <a href="HashingTF-and-CountVectorizer.html">HashingTF and CountVectorizer</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Machine Learning
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="divider"></li>
    <li class="dropdown-header">Regression</li>
    <li>
      <a href="linear-regression.html">Linear regression</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Classification</li>
    <li>
      <a href="logistic-regression.html">Logistic regression</a>
    </li>
    <li>
      <a href="decision-tree-classification.html">Decision tree classification</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">More ML methods coming soon</li>
    <li class="divider"></li>
    <li>
      <a href="https://github.com/MingChen0919/learning-apache-spark/tree/master/legacy">Legacy</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Module Tuning and Evaluation
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="divider"></li>
    <li class="dropdown-header">Module Tuning</li>
    <li>
      <a href="regularization.html">Regularization</a>
    </li>
    <li>
      <a href="k-folds-cross-validation.html">K-folds Cross Validation</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    NLP
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="nlp-and-nltk-basics.html">NLP and NLTK basics</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/MingChen0919/learning-apache-spark">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">NLP and NLTK basics</h1>
<h4 class="author"><em>Ming Chen</em></h4>
<h4 class="date"><em>6/11/2017</em></h4>

</div>


<p>A lot of examples in this article are borrowed from the book written by <strong>Bird et al. (2009)</strong>. Here I tried to implement the examples from the book with spark as much as possible.</p>
<p>Refer to the book for more details: *Bird, Steven, Ewan Klein, and Edward Loper. Natural language processing with Python: analyzing text with the natural language toolkit. &quot; O’Reilly Media, Inc.“, 2009.*</p>
<div id="basic-terminology" class="section level2">
<h2>Basic terminology</h2>
<ul>
<li><strong>text</strong>: a sequence of words and punctuation.</li>
<li><strong>frequency distribution</strong>: the frequency of words in a text object.</li>
<li><strong>collocation</strong>: a <strong>sequence of words</strong> that occur together unusually often.</li>
<li><strong>bigrams</strong>: word pairs. High frequent bigrams are collocations.</li>
<li><strong>corpus</strong>: a large body of text</li>
<li><strong>wordnet</strong>: a lexical database in which english words are grouped into sets of synonyms (<strong>also called synsets</strong>).</li>
<li><strong>text normalization</strong>: the process of transforming text into a single canonical form, e.g., converting text to lowercase, removing punctuations and so on.</li>
<li><strong>Lemmatization</strong>: the process of grouping variant forms of the same word so that they can be analyzed as a single item.</li>
<li><strong>Stemming</strong>: the process of reducing inflected words to their <strong>word stem</strong>.</li>
<li><strong>tokenization</strong>:</li>
<li><strong>segmentation</strong>:</li>
<li><strong>chunking</strong>:</li>
</ul>
</div>
<div id="texts-as-lists-of-words" class="section level2">
<h2>Texts as lists of words</h2>
<p>Create a data frame consisting of text elements.</p>
<pre class="python"><code>import pandas as pd
pdf = pd.DataFrame({
        &#39;texts&#39;: [[&#39;I&#39;, &#39;like&#39;, &#39;playing&#39;, &#39;basketball&#39;],
                 [&#39;I&#39;, &#39;like&#39;, &#39;coding&#39;],
                 [&#39;I&#39;, &#39;like&#39;, &#39;machine&#39;, &#39;learning&#39;, &#39;very&#39;, &#39;much&#39;]]
    })
    
df = spark.createDataFrame(pdf)
df.show(truncate=False)</code></pre>
<pre><code>+----------------------------------------+
|texts                                   |
+----------------------------------------+
|[I, like, playing, basketball]          |
|[I, like, coding]                       |
|[I, like, machine, learning, very, much]|
+----------------------------------------+</code></pre>
</div>
<div id="ngrams-and-collocations" class="section level2">
<h2>Ngrams and collocations</h2>
<p>Transform texts to 2-grams, 3-grams and 4-grams collocations.</p>
<pre class="python"><code>from pyspark.ml.feature import NGram
from pyspark.ml import Pipeline
ngrams = [NGram(n=n, inputCol=&#39;texts&#39;, outputCol=str(n)+&#39;-grams&#39;) for n in [2,3,4]]

# build pipeline model
pipeline = Pipeline(stages=ngrams)

# transform data
texts_ngrams = pipeline.fit(df).transform(df)</code></pre>
<pre class="python"><code># display result
texts_ngrams.select(&#39;2-grams&#39;).show(truncate=False)
texts_ngrams.select(&#39;3-grams&#39;).show(truncate=False)
texts_ngrams.select(&#39;4-grams&#39;).show(truncate=False)</code></pre>
<pre><code>+------------------------------------------------------------------+
|2-grams                                                           |
+------------------------------------------------------------------+
|[I like, like playing, playing basketball]                        |
|[I like, like coding]                                             |
|[I like, like machine, machine learning, learning very, very much]|
+------------------------------------------------------------------+

+----------------------------------------------------------------------------------+
|3-grams                                                                           |
+----------------------------------------------------------------------------------+
|[I like playing, like playing basketball]                                         |
|[I like coding]                                                                   |
|[I like machine, like machine learning, machine learning very, learning very much]|
+----------------------------------------------------------------------------------+

+---------------------------------------------------------------------------------+
|4-grams                                                                          |
+---------------------------------------------------------------------------------+
|[I like playing basketball]                                                      |
|[]                                                                               |
|[I like machine learning, like machine learning very, machine learning very much]|
+---------------------------------------------------------------------------------+</code></pre>
</div>
<div id="access-corpora-from-the-nltk-package" class="section level2">
<h2>Access corpora from the NLTK package</h2>
<p><strong>The <em>gutenberg</em> corpus</strong></p>
<pre class="python"><code>## get file ids in gutenberg corpus
gutenberg_fileids = gutenberg.fileids()
gutenberg_fileids</code></pre>
<pre><code>[u&#39;austen-emma.txt&#39;,
 u&#39;austen-persuasion.txt&#39;,
 u&#39;austen-sense.txt&#39;,
 u&#39;bible-kjv.txt&#39;,
 u&#39;blake-poems.txt&#39;,
 u&#39;bryant-stories.txt&#39;,
 u&#39;burgess-busterbrown.txt&#39;,
 u&#39;carroll-alice.txt&#39;,
 u&#39;chesterton-ball.txt&#39;,
 u&#39;chesterton-brown.txt&#39;,
 u&#39;chesterton-thursday.txt&#39;,
 u&#39;edgeworth-parents.txt&#39;,
 u&#39;melville-moby_dick.txt&#39;,
 u&#39;milton-paradise.txt&#39;,
 u&#39;shakespeare-caesar.txt&#39;,
 u&#39;shakespeare-hamlet.txt&#39;,
 u&#39;shakespeare-macbeth.txt&#39;,
 u&#39;whitman-leaves.txt&#39;]</code></pre>
<pre class="python"><code>## absolute path of a file
gutenberg.abspath(gutenberg_fileids[0])</code></pre>
<pre class="python"><code>FileSystemPathPointer(u&#39;/Users/mingchen/nltk_data/corpora/gutenberg/austen-emma.txt&#39;)</code></pre>
<pre class="python"><code>## raw text
gutenberg.raw(gutenberg_fileids[0])[:200]</code></pre>
<pre><code>u&#39;[Emma by Jane Austen 1816]\n\nVOLUME I\n\nCHAPTER I\n\n\nEmma Woodhouse, handsome, clever, and rich, with a comfortable home\nand happy disposition, seemed to unite some of the best blessings\nof existence; an&#39;</code></pre>
<pre class="python"><code>## the words of the whole corpus
gutenberg.words()</code></pre>
<pre><code>[u&#39;[&#39;, u&#39;Emma&#39;, u&#39;by&#39;, u&#39;Jane&#39;, u&#39;Austen&#39;, u&#39;1816&#39;, ...]</code></pre>
<pre class="python"><code>len(gutenberg.words())</code></pre>
<pre><code>2621613</code></pre>
<pre class="python"><code>## the sentences of a speficied file
gutenberg.sents(gutenberg_fileids[0])</code></pre>
<pre><code>[[u&#39;[&#39;, u&#39;Emma&#39;, u&#39;by&#39;, u&#39;Jane&#39;, u&#39;Austen&#39;, u&#39;1816&#39;, u&#39;]&#39;], [u&#39;VOLUME&#39;, u&#39;I&#39;], ...]</code></pre>
<pre class="python"><code>len(gutenberg.sents(gutenberg_fileids[0]))</code></pre>
<pre><code>7752</code></pre>
<p><strong>Loading custom corpus</strong></p>
<p>Let’s create a corpus consisting all files from the <strong>./data</strong> directory.</p>
<pre class="python"><code>from nltk.corpus import PlaintextCorpusReader
corpus_data = PlaintextCorpusReader(&#39;./data&#39;, &#39;.*&#39;)</code></pre>
<p>Files in the corpus <em>corpus_data</em></p>
<pre class="python"><code>data_fileids = corpus_data.fileids()
data_fileids</code></pre>
<pre><code>[&#39;Advertising.csv&#39;,
 &#39;Credit.csv&#39;,
 &#39;WineData.csv&#39;,
 &#39;churn-bigml-20.csv&#39;,
 &#39;churn-bigml-80.csv&#39;,
 &#39;cuse_binary.csv&#39;,
 &#39;horseshoe_crab.csv&#39;,
 &#39;hsb2.csv&#39;,
 &#39;hsb2_modified.csv&#39;,
 &#39;iris.csv&#39;,
 &#39;mtcars.csv&#39;,
 &#39;prostate.csv&#39;,
 &#39;twitter.txt&#39;]</code></pre>
<p>Raw text in <em>twitter.txt</em></p>
<pre class="python"><code>corpus_data.raw(&#39;twitter.txt&#39;)</code></pre>
<pre><code>u&#39;Fresh install of XP on new computer. Sweet relief! fuck vista\t1018769417\t1.0\nWell. Now I know where to go when I want my knives. #ChiChevySXSW http://post.ly/RvDl\t10284216536\t1.0\n&quot;Literally six weeks before I can take off &quot;&quot;SSC Chair&quot;&quot; off my email. Its like the torturous 4th mile before everything stops hurting.&quot;\t10298589026\t1.0\nMitsubishi i MiEV - Wikipedia, the free encyclopedia - http://goo.gl/xipe Cutest car ever!\t109017669432377344\t1.0\n\&#39;Cheap Eats in SLP\&#39; - http://t.co/4w8gRp7\t109642968603963392\t1.0\nTeenage Mutant Ninja Turtle art is never a bad thing... http://bit.ly/aDMHyW\t10995492579\t1.0\nNew demographic survey of online video viewers: http://bit.ly/cx8b7I via @KellyOlexa\t11713360136\t1.0\nhi all - i\&#39;m going to be tweeting things lookstat at the @lookstat twitter account. please follow me there\t1208319583\t1.0\nHoly carp, no. That movie will seriously suffer for it. RT @MouseInfo: Anyone excited for The Little Mermaid in 3D?\t121330835726155776\t1.0\n&quot;Did I really need to learn &quot;&quot;I bought a box and put in it things&quot;&quot; in arabic? This is the most random book ever.&quot;\t12358025545\t1.0\n&#39;</code></pre>
<p>Words and sentences in file <em>twitter.txt</em>.</p>
<pre class="python"><code>corpus_data.words(fileids=&#39;twitter.txt&#39;)</code></pre>
<pre><code>[u&#39;Fresh&#39;, u&#39;install&#39;, u&#39;of&#39;, u&#39;XP&#39;, u&#39;on&#39;, u&#39;new&#39;, ...]</code></pre>
<pre class="python"><code>len(corpus_data.words(fileids=&#39;twitter.txt&#39;))</code></pre>
<pre><code>253</code></pre>
<pre class="python"><code>corpus_data.sents(fileids=&#39;twitter.txt&#39;)</code></pre>
<pre><code>[[u&#39;Fresh&#39;, u&#39;install&#39;, u&#39;of&#39;, u&#39;XP&#39;, u&#39;on&#39;, u&#39;new&#39;, u&#39;computer&#39;, u&#39;.&#39;], [u&#39;Sweet&#39;, u&#39;relief&#39;, u&#39;!&#39;], ...]</code></pre>
<pre class="python"><code>len(corpus_data.sents(fileids=&#39;twitter.txt&#39;))</code></pre>
<pre><code>14</code></pre>
</div>
<div id="wordnet" class="section level2">
<h2>WordNet</h2>
<p>The <code>nltk.corpus.wordnet.synsets()</code> function load all synsents with a given lemma and part of speech tag.</p>
<p>Load all synsets into a spark data frame given the lemma <code>car</code>.</p>
<pre class="python"><code>pdf = pd.DataFrame({
        &#39;car_synsets&#39;: [synsets._name for synsets in wordnet.synsets(&#39;car&#39;)]
    })
df = spark.createDataFrame(pdf)
df.show()</code></pre>
<pre><code>+--------------+
|   car_synsets|
+--------------+
|      car.n.01|
|      car.n.02|
|      car.n.03|
|      car.n.04|
|cable_car.n.01|
+--------------+</code></pre>
<p><strong>Get lemma names given a synset</strong></p>
<pre class="python"><code>from pyspark.sql.functions import udf
from pyspark.sql.types import *
from nltk.corpus import wordnet

returntype = ArrayType(StringType())
synset_lemmas_udf = udf(lambda x: wordnet.synset(x).lemma_names(), returnType=returntype)
df_lemmas = df.select(&#39;car_synsets&#39;, synset_lemmas_udf(df.car_synsets).alias(&#39;lemma_names&#39;))</code></pre>
<pre class="python"><code>## display result
df_lemmas.show(truncate=False)</code></pre>
<pre><code>+--------------+------------------------------------------+
|car_synsets   |lemma_names                               |
+--------------+------------------------------------------+
|car.n.01      |[car, auto, automobile, machine, motorcar]|
|car.n.02      |[car, railcar, railway_car, railroad_car] |
|car.n.03      |[car, gondola]                            |
|car.n.04      |[car, elevator_car]                       |
|cable_car.n.01|[cable_car, car]                          |
+--------------+------------------------------------------+</code></pre>
<p><strong>Get synset definition</strong></p>
<pre class="python"><code>synset_definition_udf = udf(lambda x: wordnet.synset(x).definition(), StringType())
df_2 = df_lemmas.select(&#39;car_synsets&#39;,
                        &#39;lemma_names&#39;,
                        synset_definition_udf(df.car_synsets).alias(&#39;definition&#39;))</code></pre>
<pre class="python"><code>df_2.show()</code></pre>
<pre><code>+--------------+--------------------+--------------------+
|   car_synsets|         lemma_names|          definition|
+--------------+--------------------+--------------------+
|      car.n.01|[car, auto, autom...|a motor vehicle w...|
|      car.n.02|[car, railcar, ra...|a wheeled vehicle...|
|      car.n.03|      [car, gondola]|the compartment t...|
|      car.n.04| [car, elevator_car]|where passengers ...|
|cable_car.n.01|    [cable_car, car]|a conveyance for ...|
+--------------+--------------------+--------------------+</code></pre>
</div>

<center>Copyright &copy; 2017 Ming Chen  & Wenqiang Feng. All rights reserved.</center>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
