{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SparkContext & SparkSession "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SparkContext**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(master = 'local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SparkSession**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "          .appName(\"Python Spark SQL basic example\") \\\n",
    "          .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "          .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars = spark.read.csv(path='data/mtcars.csv',\n",
    "                        sep=',',\n",
    "                        encoding='UTF-8',\n",
    "                        comment=None,\n",
    "                        header=True, \n",
    "                        inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema = ArrayType(StructType([\n",
    "                StructField('f1', StringType()),\n",
    "                StructField('f2', StringType())\n",
    "            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='Mazda RX4', mpg=21.0, cyl=6, disp=160.0, hp=110, drat=3.9, wt=2.62, qsec=16.46, vs=0, am=1, gear=4, carb=4),\n",
       " Row(_c0='Mazda RX4 Wag', mpg=21.0, cyl=6, disp=160.0, hp=110, drat=3.9, wt=2.875, qsec=17.02, vs=0, am=1, gear=4, carb=4)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtcars.rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mazda RX4', 21.0),\n",
       " ('Mazda RX4 Wag', 21.0),\n",
       " ('Datsun 710', 22.8),\n",
       " ('Hornet 4 Drive', 21.4),\n",
       " ('Hornet Sportabout', 18.7)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtcars_map = mtcars.rdd.map(lambda x: (x['_c0'], x['mpg']))\n",
    "mtcars_map.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mazda RX4', [21.0, 210.0]),\n",
       " ('Mazda RX4 Wag', [21.0, 210.0]),\n",
       " ('Datsun 710', [22.8, 228.0]),\n",
       " ('Hornet 4 Drive', [21.4, 214.0]),\n",
       " ('Hornet Sportabout', [18.7, 187.0])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtcars_mapvalues = mtcars_map.mapValues(lambda x: [x, x * 10])\n",
    "mtcars_mapvalues.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark import RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PACKAGE_EXTENSIONS',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_accumulatorServer',\n",
       " '_active_spark_context',\n",
       " '_batchSize',\n",
       " '_callsite',\n",
       " '_checkpointFile',\n",
       " '_conf',\n",
       " '_dictToJavaMap',\n",
       " '_do_init',\n",
       " '_ensure_initialized',\n",
       " '_gateway',\n",
       " '_getJavaStorageLevel',\n",
       " '_initialize_context',\n",
       " '_javaAccumulator',\n",
       " '_jsc',\n",
       " '_jvm',\n",
       " '_lock',\n",
       " '_next_accum_id',\n",
       " '_pickled_broadcast_vars',\n",
       " '_python_includes',\n",
       " '_temp_dir',\n",
       " '_unbatched_serializer',\n",
       " 'accumulator',\n",
       " 'addFile',\n",
       " 'addPyFile',\n",
       " 'appName',\n",
       " 'applicationId',\n",
       " 'binaryFiles',\n",
       " 'binaryRecords',\n",
       " 'broadcast',\n",
       " 'cancelAllJobs',\n",
       " 'cancelJobGroup',\n",
       " 'defaultMinPartitions',\n",
       " 'defaultParallelism',\n",
       " 'dump_profiles',\n",
       " 'emptyRDD',\n",
       " 'environment',\n",
       " 'getConf',\n",
       " 'getLocalProperty',\n",
       " 'getOrCreate',\n",
       " 'hadoopFile',\n",
       " 'hadoopRDD',\n",
       " 'master',\n",
       " 'newAPIHadoopFile',\n",
       " 'newAPIHadoopRDD',\n",
       " 'parallelize',\n",
       " 'pickleFile',\n",
       " 'profiler_collector',\n",
       " 'pythonExec',\n",
       " 'pythonVer',\n",
       " 'range',\n",
       " 'runJob',\n",
       " 'sequenceFile',\n",
       " 'serializer',\n",
       " 'setCheckpointDir',\n",
       " 'setJobGroup',\n",
       " 'setLocalProperty',\n",
       " 'setLogLevel',\n",
       " 'setSystemProperty',\n",
       " 'show_profiles',\n",
       " 'sparkHome',\n",
       " 'sparkUser',\n",
       " 'startTime',\n",
       " 'statusTracker',\n",
       " 'stop',\n",
       " 'textFile',\n",
       " 'uiWebUrl',\n",
       " 'union',\n",
       " 'version',\n",
       " 'wholeTextFiles']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(x1='a', x2=3), Row(x1='b', x2=4)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([\n",
    "    Row(x1='a', x2=3),\n",
    "    Row(x1='b', x2=4)\n",
    "]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(x1='a', x2=3), Row(x1='b', x2=4), Row(x1='c', x2=5)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([\n",
    "    Row(x1='a', x2=3),\n",
    "    Row(x1='b', x2=4),\n",
    "    Row(x1='c', x2=5),\n",
    "])\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_1: string, _2: double]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "spark.createDataFrame(mtcars.rdd.map(lambda x: [x['_c0'], x['mpg']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',mpg,cyl,disp,hp,drat,wt,qsec,vs,am,gear,carb',\n",
       " 'Mazda RX4,21,6,160,110,3.9,2.62,16.46,0,1,4,4',\n",
       " 'Mazda RX4 Wag,21,6,160,110,3.9,2.875,17.02,0,1,4,4',\n",
       " 'Datsun 710,22.8,4,108,93,3.85,2.32,18.61,1,1,4,1',\n",
       " 'Hornet 4 Drive,21.4,6,258,110,3.08,3.215,19.44,1,0,3,1']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_raw = sc.textFile('data/mtcars.csv')\n",
    "rdd_raw.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model',\n",
       " 'mpg',\n",
       " 'cyl',\n",
       " 'disp',\n",
       " 'hp',\n",
       " 'drat',\n",
       " 'wt',\n",
       " 'qsec',\n",
       " 'vs',\n",
       " 'am',\n",
       " 'gear',\n",
       " 'carb']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = rdd_raw.map(lambda x: x.split(',')).filter(lambda x: x[1] == 'mpg').collect()[0]\n",
    "header[0] = 'model'\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Mazda RX4',\n",
       "  '21',\n",
       "  '6',\n",
       "  '160',\n",
       "  '110',\n",
       "  '3.9',\n",
       "  '2.62',\n",
       "  '16.46',\n",
       "  '0',\n",
       "  '1',\n",
       "  '4',\n",
       "  '4'],\n",
       " ['Mazda RX4 Wag',\n",
       "  '21',\n",
       "  '6',\n",
       "  '160',\n",
       "  '110',\n",
       "  '3.9',\n",
       "  '2.875',\n",
       "  '17.02',\n",
       "  '0',\n",
       "  '1',\n",
       "  '4',\n",
       "  '4']]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = rdd_raw.map(lambda x: x.split(',')).filter(lambda x: x[1] != 'mpg')\n",
    "rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(a=1, b=2, c=3)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(header)\n",
    "my_dict = dict(zip(['a', 'b', 'c'], range(1,4)))\n",
    "Row(**my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(am=10, carb=12, cyl=3, disp=4, drat=6, gear=11, hp=5, model=1, mpg=2, qsec=8, vs=9, wt=7)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Row(**row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(am='1', carb='4', cyl='6', disp='160', drat='3.9', gear='4', hp='110', model='Mazda RX4', mpg='21', qsec='16.46', vs='0', wt='2.62'),\n",
       " Row(am='1', carb='4', cyl='6', disp='160', drat='3.9', gear='4', hp='110', model='Mazda RX4 Wag', mpg='21', qsec='17.02', vs='0', wt='2.875'),\n",
       " Row(am='1', carb='1', cyl='4', disp='108', drat='3.85', gear='4', hp='93', model='Datsun 710', mpg='22.8', qsec='18.61', vs='1', wt='2.32')]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_rows = rdd.map(lambda x: list_to_row(header, x))\n",
    "rdd_rows.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_to_row(keys, values):\n",
    "    row_dict = dict(zip(keys, values))\n",
    "    return Row(**row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+----+----+----+---+-----------------+----+-----+---+-----+\n",
      "| am|carb|cyl|disp|drat|gear| hp|            model| mpg| qsec| vs|   wt|\n",
      "+---+----+---+----+----+----+---+-----------------+----+-----+---+-----+\n",
      "|  1|   4|  6| 160| 3.9|   4|110|        Mazda RX4|  21|16.46|  0| 2.62|\n",
      "|  1|   4|  6| 160| 3.9|   4|110|    Mazda RX4 Wag|  21|17.02|  0|2.875|\n",
      "|  1|   1|  4| 108|3.85|   4| 93|       Datsun 710|22.8|18.61|  1| 2.32|\n",
      "|  0|   1|  6| 258|3.08|   3|110|   Hornet 4 Drive|21.4|19.44|  1|3.215|\n",
      "|  0|   2|  8| 360|3.15|   3|175|Hornet Sportabout|18.7|17.02|  0| 3.44|\n",
      "+---+----+---+----+----+----+---+-----------------+----+-----+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(rdd_rows)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(model='Mazda RX4', values=[1.0, 4.0, 6.0, 160.0, 3.9, 4.0, 110.0, 21.0, 16.46, 0.0, 2.62]),\n",
       " Row(model='Mazda RX4 Wag', values=[1.0, 4.0, 6.0, 160.0, 3.9, 4.0, 110.0, 21.0, 17.02, 0.0, 2.875]),\n",
       " Row(model='Datsun 710', values=[1.0, 1.0, 4.0, 108.0, 3.85, 4.0, 93.0, 22.8, 18.61, 1.0, 2.32]),\n",
       " Row(model='Hornet 4 Drive', values=[0.0, 1.0, 6.0, 258.0, 3.08, 3.0, 110.0, 21.4, 19.44, 1.0, 3.215])]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_merged = df.rdd.map(lambda x: Row(model=x[7], values=list(map(float, x[:7] + x[8:]))))\n",
    "rdd_merged.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(float, ['1'] + ['2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------------------------------------------------------+\n",
      "|model            |values                                                           |\n",
      "+-----------------+-----------------------------------------------------------------+\n",
      "|Mazda RX4        |[1.0, 4.0, 6.0, 160.0, 3.9, 4.0, 110.0, 21.0, 16.46, 0.0, 2.62]  |\n",
      "|Mazda RX4 Wag    |[1.0, 4.0, 6.0, 160.0, 3.9, 4.0, 110.0, 21.0, 17.02, 0.0, 2.875] |\n",
      "|Datsun 710       |[1.0, 1.0, 4.0, 108.0, 3.85, 4.0, 93.0, 22.8, 18.61, 1.0, 2.32]  |\n",
      "|Hornet 4 Drive   |[0.0, 1.0, 6.0, 258.0, 3.08, 3.0, 110.0, 21.4, 19.44, 1.0, 3.215]|\n",
      "|Hornet Sportabout|[0.0, 2.0, 8.0, 360.0, 3.15, 3.0, 175.0, 18.7, 17.02, 0.0, 3.44] |\n",
      "+-----------------+-----------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_merged = spark.createDataFrame(rdd_merged)\n",
    "df_merged.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(model='Mazda RX4', x1=[1.0, 4.0, 6.0, 160.0], x2=[3.9, 4.0, 110.0, 21.0, 16.46, 0.0, 2.62]),\n",
       " Row(model='Mazda RX4 Wag', x1=[1.0, 4.0, 6.0, 160.0], x2=[3.9, 4.0, 110.0, 21.0, 17.02, 0.0, 2.875]),\n",
       " Row(model='Datsun 710', x1=[1.0, 1.0, 4.0, 108.0], x2=[3.85, 4.0, 93.0, 22.8, 18.61, 1.0, 2.32]),\n",
       " Row(model='Hornet 4 Drive', x1=[0.0, 1.0, 6.0, 258.0], x2=[3.08, 3.0, 110.0, 21.4, 19.44, 1.0, 3.215]),\n",
       " Row(model='Hornet Sportabout', x1=[0.0, 2.0, 8.0, 360.0], x2=[3.15, 3.0, 175.0, 18.7, 17.02, 0.0, 3.44])]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_columns = df_merged.rdd.map(lambda x: Row(model=x[0], x1=x[1][:4], x2=x[1][4:]))\n",
    "df_3_columns.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------------+-------------------------------------------+\n",
      "|model            |x1                    |x2                                         |\n",
      "+-----------------+----------------------+-------------------------------------------+\n",
      "|Mazda RX4        |[1.0, 4.0, 6.0, 160.0]|[3.9, 4.0, 110.0, 21.0, 16.46, 0.0, 2.62]  |\n",
      "|Mazda RX4 Wag    |[1.0, 4.0, 6.0, 160.0]|[3.9, 4.0, 110.0, 21.0, 17.02, 0.0, 2.875] |\n",
      "|Datsun 710       |[1.0, 1.0, 4.0, 108.0]|[3.85, 4.0, 93.0, 22.8, 18.61, 1.0, 2.32]  |\n",
      "|Hornet 4 Drive   |[0.0, 1.0, 6.0, 258.0]|[3.08, 3.0, 110.0, 21.4, 19.44, 1.0, 3.215]|\n",
      "|Hornet Sportabout|[0.0, 2.0, 8.0, 360.0]|[3.15, 3.0, 175.0, 18.7, 17.02, 0.0, 3.44] |\n",
      "+-----------------+----------------------+-------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(df_3_columns).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
