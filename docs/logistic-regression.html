<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Ming Chen" />


<title>Logistic Regression</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Learning Apache Spark</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Getting Start
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="divider"></li>
    <li class="dropdown-header">Installations</li>
    <li>
      <a href="install.html">Installations</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Integrate Spark</li>
    <li>
      <a href="pyspark-on-rodeo.html">Integrate spark with Rodeo</a>
    </li>
    <li>
      <a href="pyspark-on-jupyter.html">Integrate spark with Jupyter</a>
    </li>
    <li>
      <a href="spark-on-jetstream-cloud.html">Spark on jetstream cloud</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Data Preparation
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01_entry_points_to_spark.html">Entry points to spark</a>
    </li>
    <li>
      <a href="02_rdd_object.html">RDD object</a>
    </li>
    <li>
      <a href="03_dataframe_object.html">DataFrame object</a>
    </li>
    <li>
      <a href="categorical-data.html">Categorial data</a>
    </li>
    <li>
      <a href="continuous-to-categorical-variable.html">Continuous variables to categorical variables</a>
    </li>
    <li>
      <a href="HashingTF-and-CountVectorizer.html">HashingTF and CountVectorizer</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Machine Learning
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="divider"></li>
    <li class="dropdown-header">Regression</li>
    <li>
      <a href="linear-regression.html">Linear regression</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Classification</li>
    <li>
      <a href="logistic-regression.html">Logistic regression</a>
    </li>
    <li>
      <a href="decision-tree-classification.html">Decision tree classification</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">More ML methods coming soon</li>
    <li class="divider"></li>
    <li>
      <a href="https://github.com/MingChen0919/learning-apache-spark/tree/master/legacy">Legacy</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Module Tuning and Evaluation
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="divider"></li>
    <li class="dropdown-header">Module Tuning</li>
    <li>
      <a href="regularization.html">Regularization</a>
    </li>
    <li>
      <a href="k-folds-cross-validation.html">K-folds Cross Validation</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    NLP
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">NLP and NLTK basics</li>
    <li>
      <a href="hlp-and-nltk-basics.html"></a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/MingChen0919/learning-apache-spark">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Logistic Regression</h1>
<h4 class="author"><em>Ming Chen</em></h4>
<h4 class="date"><em>6/5/2017</em></h4>

</div>


<div id="logistic-regression-with-pyspark" class="section level2">
<h2>Logistic regression with pyspark</h2>
<p><strong>Import data</strong></p>
<pre class="python"><code>cuse = spark.read.csv(&#39;data/cuse_binary.csv&#39;, header=True, inferSchema=True)
cuse.show(5)

+---+---------+---------+---+
|age|education|wantsMore|  y|
+---+---------+---------+---+
|&lt;25|      low|      yes|  0|
|&lt;25|      low|      yes|  0|
|&lt;25|      low|      yes|  0|
|&lt;25|      low|      yes|  0|
|&lt;25|      low|      yes|  0|
+---+---------+---------+---+
only showing top 5 rows</code></pre>
</div>
<div id="process-categorical-columns" class="section level2">
<h2>Process categorical columns</h2>
<p>The following code does three things with pipeline:</p>
<ul>
<li><code>StringIndexer</code> all categorical columns</li>
<li><code>OneHotEncoder</code> all categorical index columns</li>
<li><code>VectorAssembler</code> all feature columns into one vector column</li>
</ul>
<pre class="python"><code>from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler
from pyspark.ml import Pipeline

# categorical columns
categorical_columns = cuse.columns[0:3]

# build StringIndexer stages
stringindexer_stages = [StringIndexer(inputCol=c, outputCol=&#39;strindexed_&#39; + c) for c in categorical_columns]
# encode label column and add it to stringindexer_stages
stringindexer_stages += [StringIndexer(inputCol=&#39;y&#39;, outputCol=&#39;label&#39;)]

# build OneHotEncoder stages
onehotencoder_stages = [OneHotEncoder(inputCol=&#39;strindexed_&#39; + c, outputCol=&#39;onehot_&#39; + c) for c in categorical_columns]

# build VectorAssembler stage
feature_columns = [&#39;onehot_&#39; + c for c in categorical_columns]
vectorassembler_stage = VectorAssembler(inputCols=feature_columns, outputCol=&#39;features&#39;) 

# all stages
all_stages = stringindexer_stages + onehotencoder_stages + [vectorassembler_stage]

# build pipeline model
pipeline = Pipeline(stages=all_stages)

# fit pipeline model
pipeline_model = pipeline.fit(cuse)

# transform the data
final_columns = feature_columns + [&#39;features&#39;, &#39;label&#39;]
cuse_df = pipeline_model.transform(cuse).\
            select(final_columns)
            
cuse_df.show(5)

+-------------+----------------+----------------+-------------------+-----+
|   onehot_age|onehot_education|onehot_wantsMore|           features|label|
+-------------+----------------+----------------+-------------------+-----+
|(3,[2],[1.0])|       (1,[],[])|   (1,[0],[1.0])|(5,[2,4],[1.0,1.0])|  0.0|
|(3,[2],[1.0])|       (1,[],[])|   (1,[0],[1.0])|(5,[2,4],[1.0,1.0])|  0.0|
|(3,[2],[1.0])|       (1,[],[])|   (1,[0],[1.0])|(5,[2,4],[1.0,1.0])|  0.0|
|(3,[2],[1.0])|       (1,[],[])|   (1,[0],[1.0])|(5,[2,4],[1.0,1.0])|  0.0|
|(3,[2],[1.0])|       (1,[],[])|   (1,[0],[1.0])|(5,[2,4],[1.0,1.0])|  0.0|
+-------------+----------------+----------------+-------------------+-----+</code></pre>
<p><strong>Split data into training and test datasets</strong></p>
<pre class="python"><code>training, test = cuse_df.randomSplit([0.8, 0.2], seed=1234)</code></pre>
<p><strong>Build cross-validation model</strong></p>
<pre class="python"><code>## ======= build cross validation model ===========

# estimator
from pyspark.ml.regression import GeneralizedLinearRegression
from pyspark.ml.classification import LogisticRegression

logr = LogisticRegression(featuresCol=&#39;features&#39;, labelCol=&#39;label&#39;)

# parameter grid
from pyspark.ml.tuning import ParamGridBuilder
param_grid = ParamGridBuilder().\
    addGrid(logr.regParam, [0, 0.5, 1, 2]).\
    addGrid(logr.elasticNetParam, [0, 0.5, 1]).\
    build()
    
# evaluator
from pyspark.ml.evaluation import BinaryClassificationEvaluator
evaluator = BinaryClassificationEvaluator(rawPredictionCol=&quot;rawPrediction&quot;)

# build cross-validation model
from pyspark.ml.tuning import CrossValidator
cv = CrossValidator(estimator=logr, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=4)</code></pre>
<p><strong>Fit model</strong></p>
<pre class="python"><code># cv_model = cv.fit(training)
# To compare the results with R, here we use the entire dataset to fit the model.
cv_model = cv.fit(cuse_df)</code></pre>
<p><strong>Prediction</strong></p>
<pre class="python"><code># prediction
show_columns = [&#39;features&#39;, &#39;label&#39;, &#39;prediction&#39;, &#39;rawPrediction&#39;, &#39;probability&#39;]

pred_training_cv = cv_model.transform(training)
pred_test_cv = cv_model.transform(test)

pred_training_cv.select(show_columns).show(5, truncate=False)
pred_test_cv.select(show_columns).show(5, truncate=False)

+---------+-----+----------+------------------------------------------+---------------------------------------+
|features |label|prediction|rawPrediction                             |probability                            |
+---------+-----+----------+------------------------------------------+---------------------------------------+
|(5,[],[])|0.0  |1.0       |[-0.05602431718564116,0.05602431718564116]|[0.4859975829890087,0.5140024170109914]|
|(5,[],[])|0.0  |1.0       |[-0.05602431718564116,0.05602431718564116]|[0.4859975829890087,0.5140024170109914]|
|(5,[],[])|0.0  |1.0       |[-0.05602431718564116,0.05602431718564116]|[0.4859975829890087,0.5140024170109914]|
|(5,[],[])|0.0  |1.0       |[-0.05602431718564116,0.05602431718564116]|[0.4859975829890087,0.5140024170109914]|
|(5,[],[])|0.0  |1.0       |[-0.05602431718564116,0.05602431718564116]|[0.4859975829890087,0.5140024170109914]|
+---------+-----+----------+------------------------------------------+---------------------------------------+
only showing top 5 rows

+---------+-----+----------+------------------------------------------+---------------------------------------+
|features |label|prediction|rawPrediction                             |probability                            |
+---------+-----+----------+------------------------------------------+---------------------------------------+
|(5,[],[])|0.0  |1.0       |[-0.05602431718564116,0.05602431718564116]|[0.4859975829890087,0.5140024170109914]|
|(5,[],[])|0.0  |1.0       |[-0.05602431718564116,0.05602431718564116]|[0.4859975829890087,0.5140024170109914]|
|(5,[],[])|0.0  |1.0       |[-0.05602431718564116,0.05602431718564116]|[0.4859975829890087,0.5140024170109914]|
|(5,[],[])|0.0  |1.0       |[-0.05602431718564116,0.05602431718564116]|[0.4859975829890087,0.5140024170109914]|
|(5,[],[])|0.0  |1.0       |[-0.05602431718564116,0.05602431718564116]|[0.4859975829890087,0.5140024170109914]|
+---------+-----+----------+------------------------------------------+---------------------------------------+
only showing top 5 rows</code></pre>
<p><strong>Estimated intercept and coefficients</strong></p>
<pre class="python"><code>print(&#39;Intercept: &#39; + str(cv_model.bestModel.intercept) + &quot;\n&quot;
     &#39;coefficients: &#39; + str(cv_model.bestModel.coefficients))
     
Intercept: 0.0560243171856
coefficients: [-0.280625539774,-0.799857435517,-1.18923909827,0.324994746147,-0.832954766261]</code></pre>
<p>See results from R</p>
<pre class="python"><code>glm_cuse$coefficients

 (Intercept)     age25-29       age&lt;25     age40-49 educationlow  wantsMoreno 
   0.7325613    0.5192319    0.9086135   -0.2806254    0.3249947   -0.8329548 </code></pre>
</div>
<div id="generalized-linear-regression-with-r" class="section level2">
<h2>Generalized linear regression with R</h2>
<pre class="r"><code>#====== This is R code! =========
cuse = read.table(&#39;http://data.princeton.edu/wws509/datasets/cuse.dat&#39;, header = T)

# convert count data to binary data
not_using = rep(1:nrow(cuse), times=cuse$notUsing)
using = rep(1:nrow(cuse), times=cuse$using)
cuse_binary = cuse[c(not_using, using), 1:3]
cuse_binary$y = c(rep(0, length(not_using)), rep(1, length(using)))

# write data into a file
write.csv(cuse_binary, file=&#39;data/cuse_binary.csv&#39;, row.names = FALSE)</code></pre>
<p><strong>Process categorical variables so they have the same pattern as in pyspar. Element levels are in the descending order of element frequencies.</strong></p>
<pre class="r"><code>#====== This is R code! =========
cuse_binary$age = factor(cuse_binary$age, 
                         levels = names(sort(table(cuse_binary$age), decreasing = TRUE)))
cuse_binary$education = factor(cuse_binary$education,
                               levels = names(sort(table(cuse_binary$education), decreasing = TRUE)))
cuse_binary$wantsMore = factor(cuse_binary$wantsMore,
                               levels = names(sort(table(cuse_binary$wantsMore), decreasing = TRUE)))

# encode label column
cuse_binary$y = factor(cuse_binary$y,
                               levels = names(sort(table(cuse_binary$y))))
glm_cuse = glm(y~age + education + wantsMore, data = cuse_binary, family = binomial(link = &quot;logit&quot;))</code></pre>
<p><strong>Resulting coefficients</strong></p>
<pre class="python"><code>#====== This is R code! =========
glm_cuse$coefficients

 (Intercept)     age25-29       age&lt;25     age40-49 educationlow  wantsMoreno 
   0.7325613    0.5192319    0.9086135   -0.2806254    0.3249947   -0.8329548 </code></pre>
</div>

<center>Copyright &copy; 2017 Ming Chen  & Wenqiang Feng. All rights reserved.</center>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
