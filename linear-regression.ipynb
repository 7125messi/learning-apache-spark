{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Linear Regression\"\n",
    "author: \"Ming Chen\"\n",
    "date: \"6/5/2017\"\n",
    "output: html_document\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "# Linear regression\n",
    "\n",
    "## Linear regression without cross-valiation\n",
    "\n",
    "**Import data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = spark.read.csv('data/Advertising.csv', header=True, inferSchema=True)\n",
    "ad.show(5)\n",
    "\n",
    "+-----+-----+---------+-----+\n",
    "|   TV|Radio|Newspaper|Sales|\n",
    "+-----+-----+---------+-----+\n",
    "|230.1| 37.8|     69.2| 22.1|\n",
    "| 44.5| 39.3|     45.1| 10.4|\n",
    "| 17.2| 45.9|     69.3|  9.3|\n",
    "|151.5| 41.3|     58.5| 18.5|\n",
    "|180.8| 10.8|     58.4| 12.9|\n",
    "+-----+-----+---------+-----+\n",
    "only showing top 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform data structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "ad_df = ad.rdd.map(lambda x: [Vectors.dense(x[0:3]), x[-1]]).toDF(['features', 'label'])\n",
    "ad_df.show(5)\n",
    "\n",
    "+-----------------+-----+\n",
    "|         features|label|\n",
    "+-----------------+-----+\n",
    "|[230.1,37.8,69.2]| 22.1|\n",
    "| [44.5,39.3,45.1]| 10.4|\n",
    "| [17.2,45.9,69.3]|  9.3|\n",
    "|[151.5,41.3,58.5]| 18.5|\n",
    "|[180.8,10.8,58.4]| 12.9|\n",
    "+-----------------+-----+\n",
    "only showing top 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build linear regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol = 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = lr.fit(ad_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Module evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator \n",
    "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='label')\n",
    "evaluator.evaluate(ad_pred, {evaluator.metricName: \"r2\"})\n",
    "\n",
    "0.897210638178952"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare results with results from R**\n",
    "\n",
    "The comparison below shows that the linear regression analyses from pyspark and R obtained very close results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intercept and coefficients from R\n",
    "advertise = read.csv('data/Advertising.csv', header = TRUE)\n",
    "lr_ad = lm(Sales~., data = advertise)\n",
    "lr_ad$coefficients\n",
    "\n",
    " (Intercept)           TV        Radio    Newspaper \n",
    " 2.938889369  0.045764645  0.188530017 -0.001037493\n",
    " \n",
    "# intercept and coefficents from pyspark\n",
    "lr_model.intercept\n",
    "\n",
    "2.9388893694594134\n",
    "\n",
    "lr_model.coefficients\n",
    "\n",
    "DenseVector([0.0458, 0.1885, -0.001])\n",
    "\n",
    "# R squared from R\n",
    "summary(lr_ad)$r.squared\n",
    "\n",
    "0.8972106\n",
    "\n",
    "# R squared from pyspark\n",
    "evaluator.evaluate(ad_pred, {evaluator.metricName: \"r2\"})\n",
    "\n",
    "0.897210638178952"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression with cross-validation\n",
    "\n",
    "**Training and test datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split data into training and test datasets\n",
    "training, test = ad_df.randomSplit([0.8, 0.2], seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build cross-validation model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##=====build cross valiation model======\n",
    "\n",
    "# estimator\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol = 'label')\n",
    "\n",
    "# parameter grid\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "param_grid = ParamGridBuilder().\\\n",
    "    addGrid(lr.regParam, [0, 0.5, 1]).\\\n",
    "    addGrid(lr.elasticNetParam, [0, 0.5, 1]).\\\n",
    "    build()\n",
    "    \n",
    "# evaluator\n",
    "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='label', metricName='r2')\n",
    "\n",
    "# cross-validation model\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit cross-validation model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = cv.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_training_cv = cv_model.transform(training)\n",
    "pred_test_cv = cv_model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance on training data\n",
    "evaluator.evaluate(pred_training_cv)\n",
    "\n",
    "0.8982486958337326\n",
    "\n",
    "# performance on test data\n",
    "evaluator.evaluate(pred_test_cv)\n",
    "\n",
    "0.8896562076565583"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intercept and coefficients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model.bestModel.intercept\n",
    "\n",
    "3.075068686285647\n",
    "\n",
    "cv_model.bestModel.coefficients\n",
    "\n",
    "DenseVector([0.0465, 0.1809, -0.0011])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get parameter values from the best model**\n",
    "\n",
    "Parameters can be extracted by calling the java property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best regParam: ' + str(cv_model.bestModel._java_obj.getRegParam()) + \"\\n\" +\n",
    "     'best ElasticNetParam:' + str(cv_model.bestModel._java_obj.getElasticNetParam()))\n",
    "     \n",
    "best regParam: 0.0\n",
    "best ElasticNetParam:0.0"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
